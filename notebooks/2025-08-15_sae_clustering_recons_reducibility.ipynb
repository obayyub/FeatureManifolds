{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a72ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import featureman.gen_data as man\n",
    "import featureman.utils as utils\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb944c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_dict = torch.load(\"sae_model_small_batch_2025-08-07_00-27-27.pth\", map_location=device)\n",
    "sae = man.BatchedSAE_Updated(input_dim=512, n_models=5, width_ratio=4).to(device)\n",
    "sae.load_state_dict(sae_dict)\n",
    "\n",
    "model_dict = torch.load(\"modular_arithmetic_model.pth\", map_location=device)\n",
    "model = man.OneLayerTransformer(p=113, d_model=128, nheads=4).to(device)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0907c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "# generate combination of all inputs a and b range (113)\n",
    "a_values = np.arange(113)\n",
    "b_values = np.arange(113)\n",
    "# generate inputs for the model\n",
    "inputs = np.array([[a_i, 113, b_i, 114] for a_i in a_values for b_i in b_values])\n",
    "inputs = torch.tensor(inputs).to(device)  # Add batch dimension\n",
    "\n",
    "logits, activations = model(inputs, return_activations=True)\n",
    "activation_final = activations[:, -1, :].detach()\n",
    "batched_acts = activation_final.unsqueeze(0).repeat(5, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b873052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "decoder = sae.W_d[3].detach() #2048 x 512\n",
    "\n",
    "_, _, feat_acts, _ = sae(batched_acts)\n",
    "features = feat_acts[3].detach() # 12769 x 512\n",
    "\n",
    "with open(\"sae_clusters_small_batch_15.pkl\", \"rb\") as f:\n",
    "    clusters = pickle.load(f)\n",
    "    clusters = [c for c in clusters if len(c) > 1]  # Filter out clusters with only one element\n",
    "\n",
    "clusters = sorted(clusters, key=lambda x: len(x), reverse=True)  # Sort by size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cfbafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_additions = inputs[:, 0] + inputs[:, 2]\n",
    "mod_additions = mod_additions % 113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67aaa43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_additions = mod_additions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23598b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Starting irreducibility analysis for 15 clusters...\n",
      "📁 Results will be saved to: irreducibility_results_20250815_220430\n",
      "Cluster   1: Size 198 - Skipped (low PC2 variance)\n",
      "Cluster   2: Size 179 - S=0.642, M=0.522 ❌\n",
      "Cluster   3: Size 152 - S=0.011, M=0.289 ❌\n",
      "Cluster   4: Size 151 - S=0.632, M=0.487 ❌\n",
      "Cluster   5: Size 150 - S=0.668, M=0.565 ❌\n",
      "Cluster   6: Size 141 - S=0.496, M=0.518 ❌\n",
      "Cluster   7: Size 139 - S=0.716, M=0.542 ❌\n",
      "Cluster   8: Size 137 - S=0.630, M=0.588 ❌\n",
      "Cluster   9: Size 123 - S=0.624, M=0.485 ❌\n",
      "Cluster  10: Size 121 - S=0.559, M=0.551 ❌\n",
      "Cluster  11: Size 118 - S=0.501, M=0.725 ❌\n",
      "Cluster  12: Size 117 - S=0.634, M=0.552 ❌\n",
      "Cluster  13: Size 116 - S=0.488, M=0.722 ❌\n",
      "Cluster  14: Size 105 - S=0.009, M=0.289 ❌\n",
      "Cluster  15: Size 101 - S=0.677, M=0.644 ❌\n",
      "\n",
      "============================================================\n",
      "📊 Summary saved to: irreducibility_results_20250815_220430/irreducibility_summary_20250815_221901.csv\n",
      "🏆 Top 5 irreducible clusters:\n",
      "   cluster_idx  irreducibility_score  mean_separability  mean_mixture  \\\n",
      "5            7              0.328060           0.715955      0.541787   \n",
      "2            4              0.324491           0.632279      0.486792   \n",
      "7            9              0.321560           0.624215      0.484857   \n",
      "0            2              0.306367           0.641523      0.522438   \n",
      "3            5              0.291120           0.668493      0.564513   \n",
      "\n",
      "   is_irreducible  \n",
      "5           False  \n",
      "2           False  \n",
      "7           False  \n",
      "0           False  \n",
      "3           False  \n",
      "🎯 Analysis complete! Check irreducibility_results_20250815_220430/ for all plots and irreducibility_results_20250815_220430/irreducibility_summary_20250815_221901.csv for summary.\n"
     ]
    }
   ],
   "source": [
    "# Import the module\n",
    "import featureman.reducibility as irr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Your updated loop\n",
    "all_summaries = []\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"irreducibility_results_{timestamp}\"\n",
    "\n",
    "print(f\"🔬 Starting irreducibility analysis for {len(clusters)} clusters...\")\n",
    "print(f\"📁 Results will be saved to: {save_dir}\")\n",
    "\n",
    "for i in range(len(clusters[:])):\n",
    "    features_cluster = features[:, clusters[i]]\n",
    "    decoder_cluster = decoder[clusters[i], :]\n",
    "    reconstructions = features_cluster @ decoder_cluster\n",
    "    reconstructions = reconstructions.detach().cpu().numpy()\n",
    "    \n",
    "    pca = PCA(n_components=6).fit(reconstructions)\n",
    "    \n",
    "    # Quick variance check\n",
    "    if pca.explained_variance_ratio_[1] < 0.1 or np.isnan(pca.explained_variance_ratio_[1]):\n",
    "        print(f\"Cluster {i+1:3d}: Size {len(clusters[i]):3d} - Skipped (low PC2 variance)\")\n",
    "        continue\n",
    "    \n",
    "    # Run silent analysis\n",
    "    summary = irr.analyze_cluster_irreducibility_silent(\n",
    "        reconstructions, \n",
    "        cluster_idx=i+1, \n",
    "        save_plots=True, \n",
    "        save_dir=save_dir\n",
    "    )\n",
    "    \n",
    "    all_summaries.append(summary)\n",
    "    \n",
    "    # Concise output\n",
    "    irreducible_flag = \"✅\" if summary['is_irreducible'] else \"❌\"\n",
    "    print(f\"Cluster {i+1:3d}: Size {len(clusters[i]):3d} - S={summary['mean_separability']:.3f}, M={summary['mean_mixture']:.3f} {irreducible_flag}\")\n",
    "\n",
    "# Save final summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "df, csv_path = irr.save_analysis_summary(all_summaries, save_dir)\n",
    "print(f\"🎯 Analysis complete! Check {save_dir}/ for all plots and {csv_path} for summary.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featuremanifolds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
