{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e508c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import featureman.gen_data as man\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd29845",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_acts, base_feats = man.generate_hidden_data(128, 512, seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b36a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_syn_acts = syn_acts.unsqueeze(0).repeat(5, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f67d4992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar-ayyub/p/FeatureManifolds/src/featureman/gen_data.py:229: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  l1_lam = torch.tensor(l1_lam, device=train_data.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0, Epoch 0, Loss: 0.0683, MSE: 0.0683, L1: 0.0000, L0: 337.9409\n",
      "Model 1, Epoch 0, Loss: 0.0690, MSE: 0.0690, L1: 0.0000, L0: 336.5731\n",
      "Model 2, Epoch 0, Loss: 0.0688, MSE: 0.0688, L1: 0.0000, L0: 333.9466\n",
      "Model 3, Epoch 0, Loss: 0.0685, MSE: 0.0685, L1: 0.0000, L0: 337.1083\n",
      "Model 4, Epoch 0, Loss: 0.0690, MSE: 0.0690, L1: 0.0000, L0: 337.2136\n",
      "Model 0, Epoch 10, Loss: 0.0648, MSE: 0.0648, L1: 0.0107, L0: 75.6708\n",
      "Model 1, Epoch 10, Loss: 0.0521, MSE: 0.0521, L1: 0.0201, L0: 128.7454\n",
      "Model 2, Epoch 10, Loss: 0.0358, MSE: 0.0358, L1: 0.0283, L0: 196.7584\n",
      "Model 3, Epoch 10, Loss: 0.0031, MSE: 0.0031, L1: 0.0007, L0: 381.6580\n",
      "Model 4, Epoch 10, Loss: 0.0037, MSE: 0.0037, L1: 0.0026, L0: 381.9676\n",
      "Model 0, Epoch 20, Loss: 0.0761, MSE: 0.0761, L1: 0.0006, L0: 5.8599\n",
      "Model 1, Epoch 20, Loss: 0.0726, MSE: 0.0726, L1: 0.0038, L0: 23.4406\n",
      "Model 2, Epoch 20, Loss: 0.0584, MSE: 0.0584, L1: 0.0150, L0: 69.2928\n",
      "Model 3, Epoch 20, Loss: 0.0009, MSE: 0.0009, L1: 0.0017, L0: 429.8640\n",
      "Model 4, Epoch 20, Loss: 0.0016, MSE: 0.0016, L1: 0.0058, L0: 397.0684\n",
      "Model 0, Epoch 30, Loss: 0.0766, MSE: 0.0766, L1: 0.0000, L0: 0.3865\n",
      "Model 1, Epoch 30, Loss: 0.0758, MSE: 0.0758, L1: 0.0007, L0: 4.9614\n",
      "Model 2, Epoch 30, Loss: 0.0657, MSE: 0.0657, L1: 0.0089, L0: 33.3282\n",
      "Model 3, Epoch 30, Loss: 0.0006, MSE: 0.0006, L1: 0.0023, L0: 449.9920\n",
      "Model 4, Epoch 30, Loss: 0.0019, MSE: 0.0019, L1: 0.0066, L0: 371.2390\n",
      "Model 0, Epoch 40, Loss: 0.0766, MSE: 0.0766, L1: 0.0000, L0: 0.1770\n",
      "Model 1, Epoch 40, Loss: 0.0754, MSE: 0.0754, L1: 0.0010, L0: 5.3387\n",
      "Model 2, Epoch 40, Loss: 0.0630, MSE: 0.0630, L1: 0.0106, L0: 29.0234\n",
      "Model 3, Epoch 40, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 454.1314\n",
      "Model 4, Epoch 40, Loss: 0.0020, MSE: 0.0020, L1: 0.0064, L0: 359.7277\n",
      "Model 0, Epoch 50, Loss: 0.0765, MSE: 0.0765, L1: 0.0000, L0: 0.3128\n",
      "Model 1, Epoch 50, Loss: 0.0747, MSE: 0.0747, L1: 0.0016, L0: 5.9662\n",
      "Model 2, Epoch 50, Loss: 0.0603, MSE: 0.0603, L1: 0.0123, L0: 25.2764\n",
      "Model 3, Epoch 50, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 454.3377\n",
      "Model 4, Epoch 50, Loss: 0.0020, MSE: 0.0020, L1: 0.0063, L0: 352.2121\n",
      "Model 0, Epoch 60, Loss: 0.0765, MSE: 0.0765, L1: 0.0001, L0: 0.4031\n",
      "Model 1, Epoch 60, Loss: 0.0740, MSE: 0.0740, L1: 0.0022, L0: 6.0019\n",
      "Model 2, Epoch 60, Loss: 0.0579, MSE: 0.0579, L1: 0.0138, L0: 22.2401\n",
      "Model 3, Epoch 60, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 454.0670\n",
      "Model 4, Epoch 60, Loss: 0.0020, MSE: 0.0020, L1: 0.0061, L0: 345.4523\n",
      "Model 0, Epoch 70, Loss: 0.0765, MSE: 0.0765, L1: 0.0001, L0: 0.4259\n",
      "Model 1, Epoch 70, Loss: 0.0733, MSE: 0.0733, L1: 0.0027, L0: 5.8337\n",
      "Model 2, Epoch 70, Loss: 0.0556, MSE: 0.0556, L1: 0.0153, L0: 19.8216\n",
      "Model 3, Epoch 70, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.8858\n",
      "Model 4, Epoch 70, Loss: 0.0019, MSE: 0.0019, L1: 0.0060, L0: 338.3434\n",
      "Model 0, Epoch 80, Loss: 0.0764, MSE: 0.0764, L1: 0.0001, L0: 0.4232\n",
      "Model 1, Epoch 80, Loss: 0.0726, MSE: 0.0726, L1: 0.0032, L0: 5.6036\n",
      "Model 2, Epoch 80, Loss: 0.0534, MSE: 0.0534, L1: 0.0166, L0: 17.8923\n",
      "Model 3, Epoch 80, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.7175\n",
      "Model 4, Epoch 80, Loss: 0.0019, MSE: 0.0019, L1: 0.0059, L0: 330.3243\n",
      "Model 0, Epoch 90, Loss: 0.0764, MSE: 0.0764, L1: 0.0001, L0: 0.4222\n",
      "Model 1, Epoch 90, Loss: 0.0721, MSE: 0.0721, L1: 0.0036, L0: 5.3201\n",
      "Model 2, Epoch 90, Loss: 0.0515, MSE: 0.0515, L1: 0.0178, L0: 16.3274\n",
      "Model 3, Epoch 90, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.5898\n",
      "Model 4, Epoch 90, Loss: 0.0018, MSE: 0.0018, L1: 0.0058, L0: 320.9736\n",
      "Model 0, Epoch 100, Loss: 0.0763, MSE: 0.0763, L1: 0.0002, L0: 0.4250\n",
      "Model 1, Epoch 100, Loss: 0.0715, MSE: 0.0715, L1: 0.0041, L0: 5.0623\n",
      "Model 2, Epoch 100, Loss: 0.0498, MSE: 0.0498, L1: 0.0189, L0: 15.0544\n",
      "Model 3, Epoch 100, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.4385\n",
      "Model 4, Epoch 100, Loss: 0.0016, MSE: 0.0016, L1: 0.0056, L0: 309.7831\n",
      "Model 0, Epoch 110, Loss: 0.0763, MSE: 0.0763, L1: 0.0002, L0: 0.4182\n",
      "Model 1, Epoch 110, Loss: 0.0711, MSE: 0.0711, L1: 0.0044, L0: 4.8181\n",
      "Model 2, Epoch 110, Loss: 0.0483, MSE: 0.0483, L1: 0.0199, L0: 14.0586\n",
      "Model 3, Epoch 110, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.2796\n",
      "Model 4, Epoch 110, Loss: 0.0013, MSE: 0.0013, L1: 0.0055, L0: 296.3842\n",
      "Model 0, Epoch 120, Loss: 0.0762, MSE: 0.0762, L1: 0.0002, L0: 0.4041\n",
      "Model 1, Epoch 120, Loss: 0.0707, MSE: 0.0707, L1: 0.0047, L0: 4.5549\n",
      "Model 2, Epoch 120, Loss: 0.0471, MSE: 0.0471, L1: 0.0207, L0: 13.3018\n",
      "Model 3, Epoch 120, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 453.0587\n",
      "Model 4, Epoch 120, Loss: 0.0011, MSE: 0.0011, L1: 0.0053, L0: 281.0952\n",
      "Model 0, Epoch 130, Loss: 0.0762, MSE: 0.0762, L1: 0.0003, L0: 0.3943\n",
      "Model 1, Epoch 130, Loss: 0.0703, MSE: 0.0703, L1: 0.0050, L0: 4.3426\n",
      "Model 2, Epoch 130, Loss: 0.0459, MSE: 0.0459, L1: 0.0214, L0: 12.6696\n",
      "Model 3, Epoch 130, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 452.8169\n",
      "Model 4, Epoch 130, Loss: 0.0008, MSE: 0.0008, L1: 0.0052, L0: 264.0945\n",
      "Model 0, Epoch 140, Loss: 0.0761, MSE: 0.0761, L1: 0.0003, L0: 0.3803\n",
      "Model 1, Epoch 140, Loss: 0.0700, MSE: 0.0700, L1: 0.0052, L0: 4.1237\n",
      "Model 2, Epoch 140, Loss: 0.0450, MSE: 0.0450, L1: 0.0221, L0: 12.1726\n",
      "Model 3, Epoch 140, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 452.5674\n",
      "Model 4, Epoch 140, Loss: 0.0005, MSE: 0.0005, L1: 0.0051, L0: 247.1545\n",
      "Model 0, Epoch 150, Loss: 0.0761, MSE: 0.0761, L1: 0.0003, L0: 0.3690\n",
      "Model 1, Epoch 150, Loss: 0.0697, MSE: 0.0697, L1: 0.0054, L0: 3.9427\n",
      "Model 2, Epoch 150, Loss: 0.0442, MSE: 0.0442, L1: 0.0226, L0: 11.7471\n",
      "Model 3, Epoch 150, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 452.3732\n",
      "Model 4, Epoch 150, Loss: 0.0003, MSE: 0.0003, L1: 0.0050, L0: 232.8558\n",
      "Model 0, Epoch 160, Loss: 0.0760, MSE: 0.0760, L1: 0.0004, L0: 0.3662\n",
      "Model 1, Epoch 160, Loss: 0.0695, MSE: 0.0695, L1: 0.0056, L0: 3.7469\n",
      "Model 2, Epoch 160, Loss: 0.0435, MSE: 0.0435, L1: 0.0231, L0: 11.4194\n",
      "Model 3, Epoch 160, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 452.1257\n",
      "Model 4, Epoch 160, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 223.8947\n",
      "Model 0, Epoch 170, Loss: 0.0760, MSE: 0.0760, L1: 0.0004, L0: 0.3471\n",
      "Model 1, Epoch 170, Loss: 0.0693, MSE: 0.0693, L1: 0.0058, L0: 3.5898\n",
      "Model 2, Epoch 170, Loss: 0.0429, MSE: 0.0429, L1: 0.0235, L0: 11.1492\n",
      "Model 3, Epoch 170, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 451.9001\n",
      "Model 4, Epoch 170, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 220.0785\n",
      "Model 0, Epoch 180, Loss: 0.0759, MSE: 0.0759, L1: 0.0004, L0: 0.3386\n",
      "Model 1, Epoch 180, Loss: 0.0691, MSE: 0.0691, L1: 0.0059, L0: 3.4313\n",
      "Model 2, Epoch 180, Loss: 0.0425, MSE: 0.0425, L1: 0.0238, L0: 10.9261\n",
      "Model 3, Epoch 180, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 451.6251\n",
      "Model 4, Epoch 180, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 218.8145\n",
      "Model 0, Epoch 190, Loss: 0.0759, MSE: 0.0759, L1: 0.0005, L0: 0.3335\n",
      "Model 1, Epoch 190, Loss: 0.0689, MSE: 0.0689, L1: 0.0060, L0: 3.2896\n",
      "Model 2, Epoch 190, Loss: 0.0421, MSE: 0.0421, L1: 0.0241, L0: 10.7401\n",
      "Model 3, Epoch 190, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 451.3431\n",
      "Model 4, Epoch 190, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 218.3659\n",
      "Model 0, Epoch 200, Loss: 0.0758, MSE: 0.0758, L1: 0.0005, L0: 0.3160\n",
      "Model 1, Epoch 200, Loss: 0.0688, MSE: 0.0688, L1: 0.0061, L0: 3.1436\n",
      "Model 2, Epoch 200, Loss: 0.0417, MSE: 0.0417, L1: 0.0243, L0: 10.5992\n",
      "Model 3, Epoch 200, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 451.1237\n",
      "Model 4, Epoch 200, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 218.0502\n",
      "Model 0, Epoch 210, Loss: 0.0758, MSE: 0.0758, L1: 0.0005, L0: 0.3057\n",
      "Model 1, Epoch 210, Loss: 0.0687, MSE: 0.0687, L1: 0.0061, L0: 3.0204\n",
      "Model 2, Epoch 210, Loss: 0.0414, MSE: 0.0414, L1: 0.0245, L0: 10.4845\n",
      "Model 3, Epoch 210, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 450.9547\n",
      "Model 4, Epoch 210, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 217.7480\n",
      "Model 0, Epoch 220, Loss: 0.0758, MSE: 0.0758, L1: 0.0006, L0: 0.2933\n",
      "Model 1, Epoch 220, Loss: 0.0686, MSE: 0.0686, L1: 0.0062, L0: 2.9026\n",
      "Model 2, Epoch 220, Loss: 0.0411, MSE: 0.0411, L1: 0.0247, L0: 10.4023\n",
      "Model 3, Epoch 220, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 450.6841\n",
      "Model 4, Epoch 220, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 217.4993\n",
      "Model 0, Epoch 230, Loss: 0.0757, MSE: 0.0757, L1: 0.0006, L0: 0.2850\n",
      "Model 1, Epoch 230, Loss: 0.0685, MSE: 0.0685, L1: 0.0062, L0: 2.7719\n",
      "Model 2, Epoch 230, Loss: 0.0408, MSE: 0.0408, L1: 0.0249, L0: 10.3100\n",
      "Model 3, Epoch 230, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 450.3412\n",
      "Model 4, Epoch 230, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 217.3287\n",
      "Model 0, Epoch 240, Loss: 0.0757, MSE: 0.0757, L1: 0.0006, L0: 0.2790\n",
      "Model 1, Epoch 240, Loss: 0.0684, MSE: 0.0684, L1: 0.0063, L0: 2.6761\n",
      "Model 2, Epoch 240, Loss: 0.0406, MSE: 0.0406, L1: 0.0250, L0: 10.2305\n",
      "Model 3, Epoch 240, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 449.9412\n",
      "Model 4, Epoch 240, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 217.2108\n",
      "Model 0, Epoch 250, Loss: 0.0756, MSE: 0.0756, L1: 0.0006, L0: 0.2722\n",
      "Model 1, Epoch 250, Loss: 0.0684, MSE: 0.0684, L1: 0.0063, L0: 2.5816\n",
      "Model 2, Epoch 250, Loss: 0.0404, MSE: 0.0404, L1: 0.0252, L0: 10.1718\n",
      "Model 3, Epoch 250, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 449.5393\n",
      "Model 4, Epoch 250, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 217.1356\n",
      "Model 0, Epoch 260, Loss: 0.0756, MSE: 0.0756, L1: 0.0007, L0: 0.2507\n",
      "Model 1, Epoch 260, Loss: 0.0683, MSE: 0.0683, L1: 0.0063, L0: 2.4863\n",
      "Model 2, Epoch 260, Loss: 0.0403, MSE: 0.0403, L1: 0.0252, L0: 10.0988\n",
      "Model 3, Epoch 260, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 449.1447\n",
      "Model 4, Epoch 260, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.9933\n",
      "Model 0, Epoch 270, Loss: 0.0756, MSE: 0.0756, L1: 0.0007, L0: 0.2469\n",
      "Model 1, Epoch 270, Loss: 0.0683, MSE: 0.0683, L1: 0.0063, L0: 2.3909\n",
      "Model 2, Epoch 270, Loss: 0.0402, MSE: 0.0402, L1: 0.0253, L0: 10.0427\n",
      "Model 3, Epoch 270, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 448.5961\n",
      "Model 4, Epoch 270, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.8268\n",
      "Model 0, Epoch 280, Loss: 0.0755, MSE: 0.0755, L1: 0.0007, L0: 0.2386\n",
      "Model 1, Epoch 280, Loss: 0.0683, MSE: 0.0683, L1: 0.0063, L0: 2.3156\n",
      "Model 2, Epoch 280, Loss: 0.0401, MSE: 0.0401, L1: 0.0254, L0: 10.0002\n",
      "Model 3, Epoch 280, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 447.8786\n",
      "Model 4, Epoch 280, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.6882\n",
      "Model 0, Epoch 290, Loss: 0.0755, MSE: 0.0755, L1: 0.0007, L0: 0.2260\n",
      "Model 1, Epoch 290, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 2.2487\n",
      "Model 2, Epoch 290, Loss: 0.0400, MSE: 0.0400, L1: 0.0255, L0: 9.9585\n",
      "Model 3, Epoch 290, Loss: 0.0005, MSE: 0.0005, L1: 0.0024, L0: 446.8865\n",
      "Model 4, Epoch 290, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.5609\n",
      "Model 0, Epoch 300, Loss: 0.0755, MSE: 0.0755, L1: 0.0008, L0: 0.2269\n",
      "Model 1, Epoch 300, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 2.1771\n",
      "Model 2, Epoch 300, Loss: 0.0399, MSE: 0.0399, L1: 0.0255, L0: 9.9214\n",
      "Model 3, Epoch 300, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 445.9749\n",
      "Model 4, Epoch 300, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.4627\n",
      "Model 0, Epoch 310, Loss: 0.0754, MSE: 0.0754, L1: 0.0008, L0: 0.2130\n",
      "Model 1, Epoch 310, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 2.1126\n",
      "Model 2, Epoch 310, Loss: 0.0399, MSE: 0.0399, L1: 0.0255, L0: 9.8864\n",
      "Model 3, Epoch 310, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 445.2828\n",
      "Model 4, Epoch 310, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.4140\n",
      "Model 0, Epoch 320, Loss: 0.0754, MSE: 0.0754, L1: 0.0008, L0: 0.2089\n",
      "Model 1, Epoch 320, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 2.0534\n",
      "Model 2, Epoch 320, Loss: 0.0398, MSE: 0.0398, L1: 0.0256, L0: 9.8652\n",
      "Model 3, Epoch 320, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 444.5522\n",
      "Model 4, Epoch 320, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.2536\n",
      "Model 0, Epoch 330, Loss: 0.0754, MSE: 0.0754, L1: 0.0008, L0: 0.2004\n",
      "Model 1, Epoch 330, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 1.9924\n",
      "Model 2, Epoch 330, Loss: 0.0397, MSE: 0.0397, L1: 0.0256, L0: 9.8492\n",
      "Model 3, Epoch 330, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 443.7134\n",
      "Model 4, Epoch 330, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 216.0772\n",
      "Model 0, Epoch 340, Loss: 0.0753, MSE: 0.0753, L1: 0.0008, L0: 0.1903\n",
      "Model 1, Epoch 340, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 1.9370\n",
      "Model 2, Epoch 340, Loss: 0.0397, MSE: 0.0397, L1: 0.0257, L0: 9.8403\n",
      "Model 3, Epoch 340, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 442.6525\n",
      "Model 4, Epoch 340, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 215.8945\n",
      "Model 0, Epoch 350, Loss: 0.0753, MSE: 0.0753, L1: 0.0008, L0: 0.1843\n",
      "Model 1, Epoch 350, Loss: 0.0682, MSE: 0.0682, L1: 0.0063, L0: 1.8846\n",
      "Model 2, Epoch 350, Loss: 0.0396, MSE: 0.0396, L1: 0.0257, L0: 9.8282\n",
      "Model 3, Epoch 350, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 441.4674\n",
      "Model 4, Epoch 350, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 215.7290\n",
      "Model 0, Epoch 360, Loss: 0.0753, MSE: 0.0753, L1: 0.0009, L0: 0.1756\n",
      "Model 1, Epoch 360, Loss: 0.0682, MSE: 0.0682, L1: 0.0062, L0: 1.8344\n",
      "Model 2, Epoch 360, Loss: 0.0395, MSE: 0.0395, L1: 0.0258, L0: 9.8229\n",
      "Model 3, Epoch 360, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 440.1197\n",
      "Model 4, Epoch 360, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 215.5618\n",
      "Model 0, Epoch 370, Loss: 0.0753, MSE: 0.0753, L1: 0.0009, L0: 0.1736\n",
      "Model 1, Epoch 370, Loss: 0.0683, MSE: 0.0683, L1: 0.0062, L0: 1.7897\n",
      "Model 2, Epoch 370, Loss: 0.0395, MSE: 0.0395, L1: 0.0258, L0: 9.8042\n",
      "Model 3, Epoch 370, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 438.6046\n",
      "Model 4, Epoch 370, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 215.4273\n",
      "Model 0, Epoch 380, Loss: 0.0753, MSE: 0.0753, L1: 0.0009, L0: 0.1724\n",
      "Model 1, Epoch 380, Loss: 0.0683, MSE: 0.0683, L1: 0.0062, L0: 1.7538\n",
      "Model 2, Epoch 380, Loss: 0.0394, MSE: 0.0394, L1: 0.0259, L0: 9.7906\n",
      "Model 3, Epoch 380, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 436.8937\n",
      "Model 4, Epoch 380, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 215.1538\n",
      "Model 0, Epoch 390, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1582\n",
      "Model 1, Epoch 390, Loss: 0.0683, MSE: 0.0683, L1: 0.0062, L0: 1.7133\n",
      "Model 2, Epoch 390, Loss: 0.0393, MSE: 0.0393, L1: 0.0259, L0: 9.7882\n",
      "Model 3, Epoch 390, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 435.1285\n",
      "Model 4, Epoch 390, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 214.9271\n",
      "Model 0, Epoch 400, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1578\n",
      "Model 1, Epoch 400, Loss: 0.0683, MSE: 0.0683, L1: 0.0062, L0: 1.6768\n",
      "Model 2, Epoch 400, Loss: 0.0393, MSE: 0.0393, L1: 0.0260, L0: 9.7805\n",
      "Model 3, Epoch 400, Loss: 0.0005, MSE: 0.0005, L1: 0.0023, L0: 433.4800\n",
      "Model 4, Epoch 400, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 214.6565\n",
      "Model 0, Epoch 410, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1516\n",
      "Model 1, Epoch 410, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.6479\n",
      "Model 2, Epoch 410, Loss: 0.0392, MSE: 0.0392, L1: 0.0260, L0: 9.7661\n",
      "Model 3, Epoch 410, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 432.1655\n",
      "Model 4, Epoch 410, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 214.4005\n",
      "Model 0, Epoch 420, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1432\n",
      "Model 1, Epoch 420, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.6188\n",
      "Model 2, Epoch 420, Loss: 0.0392, MSE: 0.0392, L1: 0.0260, L0: 9.7728\n",
      "Model 3, Epoch 420, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 430.9352\n",
      "Model 4, Epoch 420, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 214.1641\n",
      "Model 0, Epoch 430, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1406\n",
      "Model 1, Epoch 430, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5911\n",
      "Model 2, Epoch 430, Loss: 0.0392, MSE: 0.0392, L1: 0.0260, L0: 9.7572\n",
      "Model 3, Epoch 430, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 429.6655\n",
      "Model 4, Epoch 430, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.9694\n",
      "Model 0, Epoch 440, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1353\n",
      "Model 1, Epoch 440, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5776\n",
      "Model 2, Epoch 440, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7554\n",
      "Model 3, Epoch 440, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 428.3683\n",
      "Model 4, Epoch 440, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.7964\n",
      "Model 0, Epoch 450, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1334\n",
      "Model 1, Epoch 450, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5595\n",
      "Model 2, Epoch 450, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7507\n",
      "Model 3, Epoch 450, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 427.2015\n",
      "Model 4, Epoch 450, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.6469\n",
      "Model 0, Epoch 460, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1332\n",
      "Model 1, Epoch 460, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5481\n",
      "Model 2, Epoch 460, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7632\n",
      "Model 3, Epoch 460, Loss: 0.0005, MSE: 0.0005, L1: 0.0022, L0: 426.2487\n",
      "Model 4, Epoch 460, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.5270\n",
      "Model 0, Epoch 470, Loss: 0.0752, MSE: 0.0752, L1: 0.0009, L0: 0.1300\n",
      "Model 1, Epoch 470, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5333\n",
      "Model 2, Epoch 470, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7562\n",
      "Model 3, Epoch 470, Loss: 0.0004, MSE: 0.0004, L1: 0.0022, L0: 425.5936\n",
      "Model 4, Epoch 470, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.4196\n",
      "Model 0, Epoch 480, Loss: 0.0751, MSE: 0.0751, L1: 0.0009, L0: 0.1241\n",
      "Model 1, Epoch 480, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5302\n",
      "Model 2, Epoch 480, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7463\n",
      "Model 3, Epoch 480, Loss: 0.0004, MSE: 0.0004, L1: 0.0022, L0: 425.1331\n",
      "Model 4, Epoch 480, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.3494\n",
      "Model 0, Epoch 490, Loss: 0.0751, MSE: 0.0751, L1: 0.0009, L0: 0.1244\n",
      "Model 1, Epoch 490, Loss: 0.0683, MSE: 0.0683, L1: 0.0061, L0: 1.5192\n",
      "Model 2, Epoch 490, Loss: 0.0391, MSE: 0.0391, L1: 0.0261, L0: 9.7387\n",
      "Model 3, Epoch 490, Loss: 0.0004, MSE: 0.0004, L1: 0.0022, L0: 424.8403\n",
      "Model 4, Epoch 490, Loss: 0.0002, MSE: 0.0002, L1: 0.0050, L0: 213.2821\n"
     ]
    }
   ],
   "source": [
    "sae = man.BatchedSAE_Updated(input_dim=128, n_models=5, width_ratio=4).to(device)\n",
    "l1_lams = torch.tensor([1e1, 0.75e1, 0.5e1, 0.25e-1, 1e-1]).to(device)\n",
    "# train the model\n",
    "result = sae.fit(train_data = batched_syn_acts, test_data=torch.tensor([]), l1_lam=l1_lams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6210544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save sae\n",
    "torch.save(sae.state_dict(), \"sae_synthetic.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featuremanifolds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
